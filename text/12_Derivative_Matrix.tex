\section{The Derivative as a Linear Transformation}\label{sec:deriv_matrix}
We defined what it means for a real-valued function of two variables to be \emph{differentiable} in Definition \ref{def:multi_differentiability} in Section \ref{sec:total_differential}. The definition there easily extends to real-valued functions of three or more variables, but it leaves unanswered a couple of natural questions:
\begin{enumerate}
\item What about \emph{vector}-valued functions of several variables? (That is, functions $f$ with a domain $D\subseteq \mathbb{R}^n$ and range in $\mathbb{R}^m$ for some $m >1$.)
\item What is \emph{the} derivative of a function of several variables? After all, we know how to define $\fp(x)$ and $\vrp(t)$ for real or vector-valued functions of one variable.
\end{enumerate}
One might be tempted at first to simply mimic the definition of the derivative from Chapter \ref{I-chapter:derivatives}, but we quickly run into trouble, for a reason that is immediately obvious. 

\mnote{.65}{\textbf{Note:} To simplify notation, we shift focus slightly and represent points in $\mathbb{R}^n$ by their position vectors, and think of functions of several variables as functions of a vector variable. For example, we'll write $f(\vec{x})$ instead of $f(x_1,x_2,\ldots, x_n)$.}

Let $\vec{a}$ be a fixed point in $\mathbb{R}^n$, and let $\vec{h}$ represent a point $(h_1,h_2,\ldots, h_n)$. Since we're treating $\vec{h}$ and $\vec{a}$ as vectors, we can add them, and write down the limit
\[
\lim_{\vec{h}\to\vec{0}}\frac{f(\vec{a}+\vec{h})-f(\vec{a})}{\norm{\vec{h}}}.
\]
(Note that division by a vector is nonsense, so we must divide by $\norm{\vec{h}}$, not $\vec{h}$.) But of course, we know that this limit does not exist, because it depends on the direction in which $\vec{h}$ approaches $\vec{0}$! Indeed, if $\vec{h} = h\vec{i}$ or $h\vec{j}$, we get a partial derivative, and for any unit vector $\vec{u}$, setting $\vec{h}=h\vec{u}$ gives us a directional derivative, and we know from Section \ref{sec:directional_derivative} that a directional derivative depends on $\vec{u}$. It seems this approach is doomed to failure. What can we try instead?

The key to generalizing the definition of the derivative given in Definition \ref{I-def:derivative_at_a_point} in Chapter \ref{I-chapter:derivatives} is remembering the following essential property of the derivative: the derivative $\fp(a)$ is used to compute the \emph{best linear approximation} to $f$ at $a$. Indeed, the \emph{linearization}\index{linearization} of $f$ at $a$ is the linear function
\begin{equation}\label{eq_linearization}
L_a(x) = f(a) +\fp(a)(x-a).
\end{equation}
That this is the best linear approximation of $f$ at $a$ can be understood as follows: first, note that the graph $y=L_a(x)$ is simply the equation of the tangent line to $y=f(x)$ at $a$. Second, note that the difference between $f(x)$ and $L_a(x)$ vanishes faster than the difference $x-a$ as $x$ approaches $a$:
\begin{align*}
\lim_{x\to a}\frac{f(x)-L_a(x)}{x-a} &= \lim_{x\to a}\frac{f(x)-(f(a)+\fp(a)(x-a))}{x-a}\\
& = \lim_{x\to a}\left(\frac{f(x)-f(a)}{x-a}-\fp(a)\frac{x-a}{x-a}\right)\\
& = \fp(a)-\fp(a)=0.
\end{align*}
\mnote{.4}{\textbf{Note:} In general, we say that two real-valued functions of one variable $f$ and $g$ \emph{agree to first order} at $a$ if 
\[
\lim_{x\to a}\frac{\lvert f(x)-g(x)\rvert}{x-a}=0.
\]
The linearization of $f$ at $a$ is the unique linear function that agrees with $f$ to first order at $a$. Going further, we can say that $f$ and $g$ \emph{agree to order $k$} at $a$ if
\[
\lim_{x\to a}\frac{\lvert f(x)-g(x)\rvert}{(x-a)^k}=0.
\]
For example one could define the degree $n$ Taylor polynomial of a function $f$ at $a$ to be the unique polynomial of degree $n$ that agrees with $f$ to order $k$ at $a$.}

While the definition of the derivative doesn't generalize well to several variables, the notion of linear approximation does. Recall from your first course in linear algebra that, given any $m\times n$ matrix $A$, we can define a function $T$, called a \emph{linear transformation} that takes an $n\times 1$ column vector as input, and produces an $m\times 1$ column vector as output:
\[
T(\vec{x}) = A\vec{x} = A\begin{bmatrix}x_1\\x_2\\ \vdots\\x_n\end{bmatrix} = \begin{bmatrix}y_1\\y_2\\ \vdots \\y_m\end{bmatrix}=\vec{y}.
\]
In the above definition, the product $A\vec{x}$ is the usual matrix product of the $m\times n$ matrix $A$ with the $n\times 1$ matrix $\vec{x}$. In this text, we generally do not write our vectors as columns, so for a vector $\vec{x}=\langle x_1,\ldots, x_n\rangle$ we will use the notation
\[
A\cdot \vec{x} =\langle a_{11}x_1+\cdots + a_{1n}x_n, \ldots, a_{m1}x_1+\cdots +a_{mn}x_n\rangle
\]
to represent the same product in our notation. (And yes, the dot in this product is intended to remind you of the dot product between vectors: recall that the $(i,j)$-entry of a matrix product $AB$ is the dot product of the $i^{\text{th}}$ row of $A$ with the $j^{\text{th}}$ column of $B$.) We can now make the following definition.\\

\definition{def:gen_linear}{Linear function}{
 A function $T$ from $\mathbb{R}^n$ to $\mathbb{R}^m$ will be called a \sword{linear function} \index{linear function} if $T$ is of the form
 \[
 T(\vec{x}) = M\cdot \vec{x}+\vec{b}
 \]
 for some $m\times n$ matrix $M$ and vector $\vec{b}$ $\mathbb{R}^m$.}\\

If we apply the convention of representing points in terms of their position vectors to the codomain as well as the domain, we can express such a function as $f=\langle f_1,\ldots, f_n\rangle$, where each function $f_i$ is a real-valued function of $n$ variables. We want differentiability of $f$ to mean that $f$ has a linear approximation $T$ that agrees with $f$ to first order at $a$. Since $f(\vec{x})$ and $T(\vec{x})$ are now vectors, saying that $T$ is a good approximation of $f$ requires that the magnitude $\norm{f(\vec{x})-T(\vec{x})}$ is small relative to the size of $\norm{\vec{x}-\vec{a}}$.\\

\definition{def:general_differentiability}{General definition of differentiability}{Let $D$ be an open subset of $\mathbb{R}^n$ and let $f$ be a function with domain $D$ and values in $\mathbb{R}^m$. We say that $f$ is \sword{differentiable}\index{differentiable!general} at a point $\vec{a}\in D$ if there exists a linear function $T:\mathbb{R}^n\to\mathbb{R}^m$ that agrees with $f$ to first order at $\vec{a}$; that is, if
\[
\lim_{\vec{x}\to\vec{a}}\frac{\norm{f(\vec{x})-T(\vec{x})}}{\norm{\vec{x}-\vec{a}}} = 0.
\]}\\
\enlargethispate{1.5\baselineskip}

This definition is going to take a lot of unpacking. First of all, what is this mysterious function $T$? How do we compute it? Does this definition include Definition \ref{def:multi_differentiability} from Section \ref{sec:total_differential} as a special case? What about differentiability for vector-valued functions of one variable, or real-valued functions of one variable?

We will answer the first two questions in due course. The answer to the rest is, ``Yes.'' The above definition generalizes all the definitions of differentiability we've encountered so far. As a first step, let us note that for $T(\vec{x})=M\cdot \vec{x}+\vec{b}$, we must have $T(\vec{a})=f(\vec{a})$, or the limit above will not exist. Thus $M\cdot \vec{a}+\vec{b} = f(\vec{a})$, so $\vec{b}=f(\vec{a})-M\cdot \vec{a}$. This tells us that $T$ must have the following form:
\begin{align}
T(\vec{x}) &= M\cdot \vec{x} + \vec{b}\notag\\
&= M\cdot \vec{x} + (f(\vec{a}) - M\cdot \vec{a})\notag\\
& = f(\vec{a})+M\cdot (\vec{x}-\vec{a}).\label{eq_gen_linear}
\end{align}
This should ring some bells: the form of $T$ is very similar to that of the linearization given for a function of one variable in Equation \eqref{eq_linearization} above, with the matrix $M$ playing the role of $\fp(a)$. Perhaps this matrix is the derivative we seek?\pagebreak
 
%\vskip\baselineskip
\noindent\textbf{\large Real-valued functions of several variables}

Let $f:D\subseteq \mathbb{R}^n\to \mathbb{R}$ be a given function of $n$ variables (you can assume $n=1, 2$ or 3 if you prefer). Let us denote a point $(x_1,x_2,\ldots, x_n)\in\mathbb{R}^n$ using the vector $\vec x = \langle x_1,x_2,\ldots, x_n\rangle$, so that $f(\vec x) = f(x_1,x_2,\ldots,x_n)$. Let $\vec a = \langle a_1,a_2,\ldots, a_n\rangle$ denote a fixed point $(a_1,a_2,\ldots, a_n)\in D$.

In Section \ref{sec:total_differential}, we saw that differentiability means that the difference $\ddz = f(x+dx,y+dy) - f(x,y)$ can be approximated by the differential $dz = f_x(x,y)\,dx+f_y(x,y)\,dy$. Differentiability was defined to mean that the error functions $E_x$ and $E_y$, defined by
\[
E_x\,dx+E_y\,dy = \ddz -dz,
\]
go to zero as $\langle dx,dy\rangle$ goes to zero. Let's rephrase this so that it works for any number of variables. Recall that the  \emph{gradient} of $f$ at $\vec{a}\in D$ is the vector $\nabla f(\vec{a})$ defined by
 \[
 \nabla f(\vec{a}) = \left< \frac{\partial f}{\partial x_1}(\vec{a}),\frac{\partial f}{\partial x_2}(\vec{a}),\ldots, \frac{\partial f}{\partial x_n}(\vec{a})\right>.
 \]
\definition{def:multi_linearize}{The linearization of a function of several variables}{Let $f$ be continuously differentiable on some open set $D\subseteq\mathbb{R}^n$, and let $\vec{a}\in D$. The \sword{linearization} \index{linearization} of $f$ at $\vec{a}$ is the function $L_{\vec{a}}(\vec{x})$ defined by
 \[
 L_{\vec{a}}(\vec{x}) = f(\vec{a}) + \nabla f(\vec{a})\cdot (\vec{x}-\vec{a}).
 \]
}

When $n=1$, we get the linearization $L_a(x) = f(a)+f'(a)(x-a)$, which is the usual linearization from Calculus I. (You might also notice that $L_a(x)$ is the first-degree Taylor polynomial of $f$ about $x=a$. The same is true of the linearization of $f$ for more than one variable, although we will not be considering Taylor polynomials in several variables.) For $n=2$, we get the linear approximation associated to the total differential:
\begin{align*}
L_{(a,b)}(x,y) &= f(a,b)+\langle f_x(a,b),f_y(a,b)\rangle\cdot \langle x-a,y-b\rangle\\
& = f(a,b) + f_x(a,b)(x-a)+f_y(a,b)(y-b).
\end{align*}

\mnote{.5}{\textbf{Note:} If the point $\vec{a}\in D$ at which we are considering the linearization is fixed/clear in a given problem, we can drop the subscript in the notation, and simply write $L(\vec{x})$ instead of $L_{\vec{a}}(\vec{x})$.}

Compare this with Equation \eqref{eq_gen_linear} above: it seems that the gradient $\nabla f (\vec{a})$ is our matrix $M$ in this case: for a real-valued function, $m=1$, so we expect an $1\times n$ row matrix, and the gradient certainly can be interpreted to fit that description.

\mnote{.3}{\textbf{Note:} Viewing the gradient $\nabla f$ as a $1\times n$ matrix $M$, the product $M\cdot \vec{x}$ defined above is indeed exactly the same as the usual dot product $\nabla f(\vec{a})\cdot \vec{x}$.}

For real-valued functions, Definition \ref{def:general_differentiability} becomes the following:

\definition{def:real_differentiability}{Differentiability of real-valued functions}{
We say that $f$ is \sword{differentiable}\index{differentiable!real-valued function} at $\vec{a}\in D$ if $\nabla f(\vec{a})$ exists, and $f(\vec{x})$ and $L_{\vec{a}}(\vec{x})$ agree to first order at $\vec{a}$; that is, if
\[
\lim_{\vec{x}\to \vec{a}}\frac{\lvert f(\vec{x})-L_{\vec{a}}(\vec{x})\rvert}{\lVert \vec{x}-\vec{a}\rVert} = \lim_{\vec{x}\to\vec{a}}\frac{\lvert f(\vec{x})-f(\vec{a})-\nabla f(\vec{a})\cdot \langle \vec{x}-\vec{a}\rangle\rvert}{\lVert\vec{x} - \vec{a}\rVert} = 0.
\]}\\

What this definition says is that the linearization $L_{\vec{a}}(\vec{x})$ is a good linear approximation to $f$ at $\vec{a}$. In fact, it's the {\em only} (and hence, best) linear approximation: if a linear approximation exists, it has to be $L_{\vec{a}}(\vec{x})$. If you want to see why this has to be true, recall that since the above limit exists, we have to be able to evaluate it along any path we like. Suppose we chose the path 
\[
\vec{r}(t) = \langle h,a_2,\ldots, a_n\rangle.
\]
Then $\vec{x}-\vec{a} = \langle h,0,\ldots, 0\rangle = h\vec{i}$, and our definition becomes:
\[
\lim_{h\to 0}\left\lvert\frac{f(a_1+h,a_2,\ldots, a_n)-f(a_1,a_2,\ldots, a_n)}{h} - \frac{\partial f}{\partial x_1}(a_1,a_2,\ldots, a_n)\right\rvert = 0,
\]
which is just another way of stating the definition of the partial derivative with respect to $x_1$. Of course, approaching along any of the other coordinate directions will similarly produce the other partial derivatives.


%\begin{remark}
%When $n=1$, we have that $\nabla f(a) = f'(a)$ (a vector with one only component is just a number), and existence of $f'(a)$ immediately implies differentiability: since by definition we have
%\[
%f'(a) = \lim_{x\to a}\frac{f(x)-f(a)}{x-a},
%\]
%it follows from the limit laws that
%\begin{align*}
%0 = \lim_{x\to a}\frac{f(x)-f(a)}{x-a} - f'(a) &= \lim_{x\to a}\left(\frac{f(x)-f(a)}{x-a} - \frac{f'(a)(x-a)}{x-a}\right)\\
%& = \lim_{x\to a}\frac{f(x)-f(a)-f'(a)(x-a)}{x-a}.
%\end{align*}
%If we try to take $\nabla f(\vec{a})$ out of the limit to get an expression like that for $f'(a)$, we immediately run into trouble, since we end up with the term $\nabla f(\vec{a})\cdot\left(\dfrac{\vec{x}-\vec{a}}{\lVert\vec{x}-\vec{a}\rVert}\right)$: in the numerator we have the dot product with the vector $\vec{x}-\vec{a}$, while in the denominator we have the length of that vector. The only time that these cancel is when $n=1$. (You might be tempted to write the dot product as $\lVert\nabla f(\vec{a})\rVert\lVert\vec{x}-\vec{a}\rVert\cos\theta$, so that the $\lVert\vec{x}-\vec{a}\rVert$ terms cancel, but we would still have the problem that $\cos\theta$ depends on the way in which $\vec{x}$ approaches $\vec{a}$.)
%\end{remark}
Recall that in one variable, the derivative is often written instead in terms of $h=x-a$, so that
\[
f'(a) = \lim_{h\to 0}\frac{f(a+h)-f(a)}{h}.
\]
\mnote{.7}{\textbf{Note:}
Recall that $\lVert \vec{x}-\vec{a}\rVert = \sqrt{(x_1-a_1)^2+\cdots +(x_n-a_n)^2}$ is the distance from $\vec{x}$ to $\vec{a}$. In general, we would say that two functions $f(\vec{x})$ and $g(\vec{x})$ ``agree up to order $k$'' at $\vec{a}$ if
\[
\lim_{\vec{x}\to\vec{a}}\frac{f(\vec{x})-g(\vec{x})}{\lVert \vec{x}-\vec{a}\rVert^k} = 0.
\]
{\bf Exercise:} Check that, for $n=1$, two functions $f$ and $g$ agree up to order $k$ at $a$ if and only if their degree $k$ Taylor polynomials are equal. (A similar statement is true in more than one variable.)
}
In more than one variable, we can define $h_i = x_i-a_i$, for $i=1,\ldots, n$, or the corresponding vector $\vec{h} = \vec{x}-\vec{a}$. The definition of differentiability then can be written as
\begin{equation}\label{eq_deriv_with_h}
\lim_{\vec{h}\to \mathbf{0}}\frac{\lvert f(\vec{a}+\vec{h})-f(\vec{a})-\nabla f(\vec{a})\cdot\vec{h}\rvert}{\lVert \vec{h}\rVert} = 0.
\end{equation}
Note that we want the difference between $f(\vec{a}+\vec{h})$ and $L_{\vec{a}}(\vec{h})$ to go to zero faster than $\lVert \vec{h}\rVert$ goes to zero, and that it only makes sense to divide by the length of $\vec{h}$, since division by a vector (or the corresponding point) is not defined.

Let's return to $n=2$ and Definition \ref{def:multi_differentiability} from Section \ref{sec:total_differential}. If we write $\vec{h} = \langle dx, dy\rangle$, then $f(\vec{a}+\vec{h})-f(\vec{a}) = \ddz$, and $\nabla f(\vec{a})\cdot \vec{h} = dz$, and Equation \eqref{eq_deriv_with_h} becomes
\[
\lim_{\vec{h}\to\vec{0}}\frac{\lvert \ddz-dz\rvert}{\norm{\vec{h}}} = \lim_{\vec{h}\to\vec{0}}\frac{\lvert E_x\,dx+E_y\,dz}{\norm{\langle dx,dy\rangle}} = 0,
\]
which is another way of saying that the error terms $E_x,E_y$ must vanish as $dx$ and $dy$ approach zero. Success! Definition \ref{def:general_differentiability} is indeed a generalization of Definition \ref{def:multi_differentiability}.

Note that we've also generalized Definition \ref{I-def:derivative_at_a_point} for functions of one variable as well: Equation \eqref{eq_deriv_with_h} becomes
\[
\lim_{h\to 0}\left\lvert \frac{f(a+h)-f(a)}{h}-f'(a)\right\rvert = 0,
\]
which is just another way of re-writing the usual definition of the derivative. In fact, we've also generalized Definition \ref{III-def:vvf_derivative} from Chapter \ref{chap:vvf} for differentiability of vector-valued functions: all we have to do is write our vector-valued function as a column matrix. For
\[
\vec{r}(t) = \begin{bmatrix}x_1(t)\\x_2(t)\\\vdots \\x_m(t)\end{bmatrix} \quad \text{ and } \quad \vrp(t) = \begin{bmatrix}x_1\primeskip'(t)\\x_2\primeskip'(t)\\\vdots \\x_m\primeskip'(t)\end{bmatrix},
\]
we have
\[
\lim_{h\to 0}\left\lVert \frac{1}{h}(\vec{r}(a+h)-\vec{r}(a))- \vrp(a)\right\rVert = 0,
\]
which again reproduces the definition of $\vrp(a)$.

One of the results we learn in Calculus I is that differentiability implies continuity. The situation is no different in general, and with our new definition of differentiability, an easy proof is possible.

\theorem{thm:gen_diff_cont}{Differentiability implies continuity}{
If $f:D\subseteq \mathbb{R}^n\to \mathbb{R}$ is differentiable at $\vec{a}\in D$, then $f$ is continuous at $\vec{a}$.}\\

\noindent\emph{Proof:}
Suppose that $f$ is differentiable at $\vec{a}$. Then we know that
\[
\lim_{\vec{x}\to \vec{a}}\frac{f(\vec{x})-L_{\vec{a}}(\vec{x})}{\lVert \vec{x}-\vec{a}\rVert} = \lim_{\vec{x}\to\vec{a}}\frac{f(\vec{x})-f(\vec{a})-\nabla f(\vec{a})\cdot \langle \vec{x}-\vec{a}\rangle}{\lVert\vec{x} - \vec{a}\rVert} = 0.
\]
By the definition of continuity, we need to show that $\displaystyle \lim_{\vec{x}\to\vec{a}}f(\vec{x}) = f(\vec{a})$. We have that
\begin{align*}
f(\vec{x}) & = f(\vec{a}) + (f(\vec{x})-f(\vec{a}))\\
 & = f(\vec{a}) + \left(f(\vec{x}) - f(\vec{a}) - \nabla f(\vec{a})\cdot (\vec{x}-\vec{a})\right) + \nabla f(\vec{a})\cdot (\vec{x}-\vec{a})\\
 & = f(\vec{a}) +\left(\frac{f(\vec{x})-f(\vec{a})-\nabla f(\vec{a})\cdot (\vec{x}-\vec{a})}{\lVert\vec{x}-\vec{a}\rVert}\right)(\lVert\vec{x}-\vec{a}\rVert) + \nabla f(\vec{a})\cdot (\vec{x}-\vec{a}).
\end{align*}
Thus, taking limits of the above as $\vec{x}\to\vec{a}$, we find $\displaystyle \lim_{\vec{x}\to\vec{a}}f(\vec{x}) = f(\vec{a})$, since the first term is a constant ($f(\vec{a})$), the second is the product of two terms that both go to zero (the first term is zero by the definition of differentiability, and clearly $\lim_{\vec{x}\to\vec{a}}\lVert\vec{x}-\vec{a}\rVert = 0$), and the last term vanishes since it's linear (and thus continuous) in $\vec{x}$, and so, by direct substitution, 
\[
\lim_{\vec{x}\to\vec{a}}\nabla f(\vec{a})\cdot(\vec{x}-\vec{a}) = \nabla f(\vec{a})\cdot(\vec{a}-\vec{a}) = 0.
\]



\vskip\baselineskip
\noindent\textbf{\large Vector-valued functions}

Let us now consider Definition \ref{def:general_differentiability} for general functions $f:D\subseteq \mathbb{R}^n\to \mathbb{R}^m$.  If $f$ is differentiable at $\vec{a}$, then we must have
\[
 \lim_{\vec{x}\to\vec{a}}\frac{\norm{f(\vec{x})-T(\vec{x})}}{\norm{\vec{x}-\vec{a}}} = 0
\]
for some linear function $T(\vec{x})$. We saw in Equation \eqref{eq_gen_linear} above that $T$ must have the form of a linear approximation:
\[
T(\vec{x})=L_{\vec{a}}(\vec{x}) = f(\vec{a})+M\cdot (\vec{x}-\vec{a}).
\]
%\mnote{.4}{\textbf{Note:} To keep everything straight, in this exposition we are going to write our vectors as column matrices rather than using angle bracket notation.}
Moreover, we'll see below that (a) the matrix $M$ is uniquely defined, and (b) $M$ is deserving of the title of ``the'' derivative of $f$.

Let's compare again to the one variable case: $L_a(x)=f(a)+f'(a)(x-a)$. With this in mind, the matrix $M$, whatever it is, certainly seems to play the role of the derivative for general functions from $\mathbb{R}^n$ to $\mathbb{R}^m$. It remains to determine the matrix $M$, and see that there can only be one possibility. To that end, let us write
\[
M = \begin{bmatrix}
c_{11} & c_{12} & \cdots & c_{1n}\\
c_{21} & c_{22} & \cdots & c_{2n}\\
\vdots & \vdotds & \ddots & \vdots\\
c_{m1} & c_{m2} & \cdots & c_{mn}\end{bmatrix},
\]
and consider what happens when we let $\vec{x}\to\vec{a}$ along different paths. If we consider the path $x_1 = a_1+t, x_2=a_2, \ldots, x_n=a_n$ (that is, varying $x_1$ while holding the other variables constant) then
\[
 \vec{x} - \vec{a} = \langle a_1+t,a_2,\ldots, a_n\rangle - \langle a_1,a_2,\vdots ,a_n\rangle = \langle t, 0, \ldots, 0\rangle.
\]
so $M\cdot (\vec{x}-\vec{a})$ gives us $t$ times the first column of $M$, since for each row of $M$, the first entry is multiplied by $t$, and the remaining entries are multiplied by zero. Thus, 
\[
M\cdot (\vec{x}-\vec{a}) = \langle c_{11}, c_{21}, \ldots, c_{m1}\rangle
\]
along this path. Now we consider the limit as $t\to 0$. 
\[
 \lim_{t\to 0}\left[\lvert\frac{f(a_1+t,a_2,\ldots, a_n)-f(a_1,a_2,\ldots, a_n)}{t} - \langle c_{11}, c_{21}, \ldots, c_{m1}\rangle\right\rvert = 0. 
\]
Since $\langle c_{11}, c_{21}, \ldots, c_{m1}\rangle$ is a constant vector, from differentiability of $f$, together with Definition \ref{def:general_differentiability}, we get
\[
\lim_{t\to 0}\frac{f(a_1+t,a_2,\ldots, a_n)-f(a_1,a_2,\ldots, a_n)}{t} = \langle c_{11}, c_{21}, \ldots, c_{m1}\rangle.
\]
But this limit on the left is just the partial derivative of $f$ with respect to $x_1$!
If we write $f(\vec{x}) = \langle f_1(\vec{x}),f_2(\vec{x}),\ldots, f_m(\vec{x})\langle$, then we have
\[
 \lim_{t\to 0}\frac{f(a_1+t,a_2,\ldots, a_n)-f(a_1,a_2,\ldots, a_n)}{t} = \\left\langle\frac{\partial f_1}{\partial x_1}(\vec{a}), \frac{\partial f_2}{\partial x_1}(\vec{a}), \ldots, \frac{\partial f_m}{\partial x_1}(\vec{a})\right\rangle,
\]
and this gives us the first column of $M$! Repeating this for each variable, we see that the matrix $M$ is exactly the matrix of all the partial derivatives of $f$. This matrix is important enough to have a name:

\definition{def:jacobian_matrix}{The Jacobian matrix of a differentiable function}{Let $D\subseteq \mathbb{R}^n$ be an open subset, and let $f:D\to \mathbb{R}^m$ be a differentiable function. At any point $\vec{a}\in D$,  the \sword{Jacobian matrix}\index{matrix!Jacobian}\index{Jacobian matrix} of $f$ at $\vec{a}$, denoted $Df(\vec{a})$, is the $m\times n$ matrix defined by
\[
Df(\vec{a}) = \begin{bmatrix}\frac{\partial f_1}{\partial x_1} & \cdots & \frac{\partial f_1}{\partial x_n}\\
                  \vdots & \ddots & \vdots \\
		  \frac{\partial f_m}{\partial x_1} & \cdots & \frac{\partial f_m}{x_n}
                 \end{bmatrix}.
\]
The linear transformation $T_{f,\vec{a}}:\mathbb{R}^n\to \mathbb{R}^m$ defined by $T_{f,\vec{a}}(\vec{x})=Df(\vec{a})\cdot \vec{x}$ is defined to be the \sword{derivative of $f$ at $\vec{a}$}\index{derivative!general}.
}

Notice that if $f$ is differentiable, the Jacobian matrix is the only matrix that can fit the definition: the fact that the limit must be zero along a path parallel to one of the coordinate axes forces the matrix $M$ to contain the partial derivatives of $f$.

In particular, note that for a function $f:\mathbb{R}^n\to \mathbb{R}$, we recover the gradient vector. (Technically, the derivative in this sense is a \emph{row} vector (some might say \emph{dual vector}), not a column vector.  Note that multiplying a row vector by a column vector is the same as taking the dot product of two column vectors. 

This definition also accounts for parametric curves, viewed as vector-valued functions of one variable. If $\mathbf{r}:\mathbb{R}\to \mathbb{R}^n$ defines a parametric curve, then the derivative $\mathbf{r}'(t) = \begin{bmatrix}x_1'(t)\\x_2'(t)\\\vdots \\x_n'(t)\end{bmatrix}$ as introduced in Calculus III is the same as the one obtained using this definition.


